<!DOCTYPE html>
<html>
<head>
  <meta name="google-site-verification" content="-3mH_RujBdPpCM6ODMxouIbc3cvIBDWZWLOW3SvuSNg" />
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>MARG</title>
  <link rel="icon" type="image/x-icon" href="static/images/MARG.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <!-- MathJax -->
  <script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
    <script id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>
</head>
<body>


  <!-- 1. Title here -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title"><font color="##0066CC">MARG</font> : <font color="##0066CC">MA</font>stering <font color="##0066CC">R</font>isky <font color="##0066CC">G</font>ap Terrains for Legged Robots with Elevation Mapping</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Yinzhao Dong</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Ji Ma</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Liu Zhao</a>,</span>
                    <span class="author-block">
                      <a href="FOURTH AUTHOR PERSONAL LINK" target="_blank">Wanyue Li</a>,</span>
                      <span class="author-block">
                        <a href="FIFTH AUTHOR PERSONAL LINK" target="_blank">Peng Lu</a><sup>†</sup>,</span>
                        <span class="author-block">
                        </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <!-- <span class="author-block">Institution Name<br>Conferance name and year</span> -->
                    <span class="author-block">The University of Hong Kong</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution</small></span>
                    <span class="eql-cntrb"><small><br><sup>†</sup>Corresponding author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                                           <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://ieeexplore.ieee.org/document/11196002" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
                                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://youtu.be/cVeQD845ER0" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/arclab-hku/Risky_gym.git" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code(Comming Soon)</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/head.mp4"
        type="video/mp4">
      </video>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Deep Reinforcement Learning (DRL) controllers for quadrupedal locomotion have demonstrated impressive performance on challenging terrains, allowing robots to execute complex skills such as climbing, running, and jumping. 
            However, existing blind controllers often struggle to ensure safety
            and efficient traversal through risky gap terrains, which are typically highly complex, requiring robots to perceive terrain information and select appropriate footholds during locomotion accurately. Meanwhile, existing perception-based controllers still present several practical limitations, including a complex multi-sensor deployment system and expensive computing resource requirements. This paper proposes a DRL controller named MAstering Risky Gap Terrains (MARG), which integrates terrain maps and proprioception to dynamically adjust the action and enhance the robot's stability in these tasks. During the training phase, our controller accelerates policy optimization by selectively incorporating privileged information (e.g., center of mass, friction coefficients) that are available in simulation but unmeasurable directly in real-world deployments due to sensor limitations. We also designed three foot-related rewards to encourage the robot to explore safe footholds. More importantly, a terrain map generation (TMG) model is proposed to reduce the drift existing in mapping and provide accurate terrain maps using only one LiDAR, providing a foundation for zero-shot transfer of the learned policy. The experimental results indicate that MARG maintains stability in various risky terrain tasks.          
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- extreme terrain -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="columns has-text-left">
            <h2 class="title">Extreme Terrain</h2>
          </div>
      <img src="static/images/extreme_terrains.png" alt="extreme_terrain">
      <h2 class="subtitle has-text-centered">
        The extreme parkour terrain, including hurdle, step, single plank bridge, ramp, narrow balance beams, and inclined balance beams.
      </h2>

      <!-- terrain sim video -->
      <div class="content has-text-left">
        To adapt to a wider range of terrain and increase the difficulty of risky gap terrain, we designed a new parkour terrain, as illustrated in Figure. This designed terrain encompasses <b>60 cm</b> high hurdles, <b>77 cm</b> high steps, a <b>10 cm</b> wide single plank bridge, <b>43.5°</b> ramps, <b>5 cm</b> wide narrow balance beams, and <b>5 cm</b> wide inclined balance beams. We concurrently train 4096 Unitree Go2 robots on these new terrains, and the video vividly showcases the final results, providing compelling evidence that our controller can successfully traverse these extreme terrains.
      </div>
              <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-video1">
            <video poster="" id="video1" autoplay controls muted loop height="100%">
              <!-- Your video file here -->
              <source src="static/videos/con/beams2.mp4"
              type="video/mp4">
            </video>
          </div>
          <div class="item item-video2">
            <video poster="" id="video2" autoplay controls muted loop height="100%">
              <!-- Your video file here -->
              <source src="static/videos/con/bridge1.mp4"
              type="video/mp4">
            </video>
          </div>
          <div class="item item-video3">
            <video poster="" id="video3" autoplay controls muted loop height="100%">\
              <!-- Your video file here -->
              <source src="static/videos/con/hurdle.mp4"
              type="video/mp4">
            </video>
          </div>
          <div class="item item-video4">
            <video poster="" id="video4" autoplay controls muted loop height="100%">\
              <!-- Your video file here -->
              <source src="static/videos/con/rot_beams2.mp4"
              type="video/mp4">
            </video>
          </div>
          <div class="item item-video5">
            <video poster="" id="video5" autoplay controls muted loop height="100%">\
              <!-- Your video file here -->
              <source src="static/videos/con/step1.mp4"
              type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </div>
  </div>
  </section>


<!-- conventional terrain -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="columns has-text-left">
            <h2 class="title">Conventional Terrain</h2>
          </div>
      <img src="static/images/conventional_terrain.png" alt="Extreme Terrain">
      <h2 class="subtitle has-text-centered">The conventional challenge terrain of 10 different levels, including slope, pyramid slope, stairs down,
        stairs up, and discrete obstacles.</h2>
      <img src="static/images/conventional_reward.png" alt="Extreme Terrain" >
      <h2 class="subtitle has-text-centered">
        The average rewards of six controllers on 4096 Unitree Go1 robots in conventional challenge terrain over 6000 episodes. Each curve's shaded region represents the standard deviation of reward values across 5 different random seeds, indicating the uncertainty in the results.
      </h2>

      <div class="content has-text-left">
        We generated a traditional challenging terrain, as shown in Figure inspired by the state-of-the-art quadrupedal locomotion controllers, including (<b>MorAL</b> , <b>Vanilla PPO</b>, <b>Concurrent</b> , <b>RMA</b> , and <b>DreamWaQ</b> ). We also utilized a game-inspired curriculum to ensure progressive locomotion policy learning over challenging terrains. As shown in Figure, the performance of these six controllers is highly consistent with that of the risky task. For example, MARG still exhibits the best performance over challenging terrains. MorAL and DreamWaQ exhibit better average rewards than Concurrent, Vanilla PPO, and RMA. Overall, these experiments demonstrate that MARG has significant advantages, whether for risky or conventional challenging terrain. This is attributed to MARG not only acquiring the explicit estimation but also the terrain map \(\boldsymbol{h}_{t}\) surrounding the robot, which facilitates the policy to reason about the robot's states.
      </div>
      </div>
    </div>
  </div>
  </div>
  </section>


<!-- Success rate -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="columns has-text-left">
            <h2 class="title">Success Rate</h2>
          </div>
      <img src="static/images/succ_gap.png" alt="Extreme Terrain">
      <h2 class="subtitle has-text-centered">Real-world tests of marg on Unitree Go2 in complex terrains, including narrow balance beams, outdoor single gap, narrow ditch, soft step, single plank bridge, indoor single gap, drainage ditch, and step.</h2>
      <img src="static/images/succ_tab.png" alt="Extreme Terrain" >
      <h2 class="subtitle has-text-centered">
        Success Rate of MARG in Risky Terrain.
      </h2>

      <div class="content has-text-left">
      We deployed MARG onto the Unitree Go2 robot and conducted multiple tests on various gap terrains. For each test, we recorded whether the robot successfully traversed the terrain, and the results are presented in table, which clearly shows the number of tests, the number of successful traversals, and the calculated success rate for each terrain type. For instance, for the outdoor Single gap, we conducted 5 tests, with 4 successful traversals, achieving a success rate of approximately <b>80%</b>. This data vividly reflects the adaptability and stability of the MARG in dealing with such gap terrains. However, for some extremely complex terrains like the 9 cm narrow balance beams, the success rate was relatively low, indicating that there is still room for improvement in the MARG algorithm.

      $$
      \bar{v}^n_i = \frac{1}{n} \sum_{t=1}^{n} (\hat{v}_{i,t} - v_{i,t})^2
      $$

      where \(i=1,2,3\) denotes different random seeds; \(\bar{v}^n_i\), \(\hat{v}_{i,t}\), and \(v_{i,t}\) represent the average squared error of the seed \(i\) over \(n\) time steps, the estimated linear velocity, and the real linear velocity, respectively. To evaluate the estimators' performance and robustness of different algorithms, we further calculated the mean \(\bar{V}\) and standard deviation \(\delta\) of the three seeds means:

      $$
      \bar{V} =\frac{1}{3}\sum_{i = 1}^{3}\bar{v}^n_i; \delta = \sqrt{\frac{1}{2}\sum_{i = 1}^{3}(\bar{v}^n_i-\bar{V})^2}
      $$
      The results are summarized in Table, which presents the average squared linear velocity errors and their standard deviations for each algorithm at different time steps. Notably, the MARG algorithm consistently demonstrates the smallest error and the lowest standard deviation across all tested steps. This performance highlights that MARG's estimator net achieves exceptional precision and robustness in gap terrain scenarios.
      </div>
    </div>
    </div>
  </div>
  </div>
  </section>

  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">

        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="columns has-text-left">
              <h2 class="title">Performance over gap terrains</h2>
            </div>
          <div class="columns">
          <div class="column">
            <div class="item item-video2">
              <video poster="" id="video2" autoplay controls muted loop height="100%">
                <!-- Your video file here -->
                <source src="static/videos/sim_1.mp4"
                type="video/mp4">
              </video>
            </div>
          </div>

          <div class="column">
            <div class="item item-video2">
              <video poster="" id="video2" autoplay controls muted loop height="100%">
                <!-- Your video file here -->
                <source src="static/videos/sim_2.mp4"
                type="video/mp4">
              </video>
            </div>
          </div>
        </div>
      </div>

      </div>
    </div>
    </div>
    </section>
   
<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@ARTICLE{11196002,
  author={Dong, Yinzhao and Ma, Ji and Zhao, Liu and Li, Wanyue and Lu, Peng},
  journal={IEEE Transactions on Robotics}, 
  title={MARG: MAstering Risky Gap Terrains for Legged Robots With Elevation Mapping}, 
  year={2025},
  volume={41},
  number={},
  pages={6123-6139},
  keywords={Robots;Robot sensing systems;Legged locomotion;Feature extraction;Computational modeling;Quadrupedal robots;Laser radar;Foot;Dynamics;Accuracy;Deep reinforcement learning (DRL);elevation mapping;legged robots;risky gap terrains},
  doi={10.1109/TRO.2025.3619041}}

</code></pre>
    </div>
</section>

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
