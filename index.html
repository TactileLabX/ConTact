<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="ConTact: Contrastive Tactile Alignment for Sim-to-Real Robotic Manipulation">
  <meta property="og:title" content="ConTact: Sim-to-Real Tactile Manipulation"/>
  <meta property="og:description" content="A contrastive learning framework to bridge the sim-to-real gap for tactile-driven robotic manipulation."/>
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>ConTact: Contrastive Tactile Alignment</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <font color="#0066CC">ConTact</font>: <font color="#0066CC">Con</font>trastive <font color="#0066CC">Tact</font>ile Alignment for Sim-to-Real Robotic Manipulation
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="#" target="_blank">Yanlin Lai</a><sup>1,2,*</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Yinzhao Dong</a><sup>1,*,†</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Chun Yuan</a><sup>2,†</sup></span>
                <span class="author-block">
                  <a href="#" target="_blank">Cheng Zhou</a><sup>1</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Tencent Robotics X,</span>
              <span class="author-block"><sup>2</sup>Tsinghua University</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution</small></span>
              <span class="eql-cntrb"><small><br><sup>†</sup>Corresponding author</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="#" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="#" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fab fa-youtube"></i></span>
                    <span>Video</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Deep reinforcement learning (DRL) has achieved remarkable success in robot control. However, DRL with tactile feedback still faces challenges in contact-rich tasks involving visual occlusion or high-speed dynamics. The challenges stem from the complexity of real-world tactile sensors and the computational intensity of high-fidelity simulators. 
            </p>
            <p>
              To address this, we design a high-speed tactile simulation model, enabling efficient, large-scale DRL training on GPUs. We then propose the <strong>Contrastive Tactile (ConTact)</strong> framework, which leverages contrastive learning to align tactile features for sim-to-real transfer. ConTact employs a dedicated spatiotemporal encoder that explicitly models temporal changes to capture the dynamic features of contact events. 
            </p>
            <p>
              We validate it on two manipulation tasks, Single and Composite Object Tracking (SOT/COT), which rely solely on tactile information. Policies trained with ConTact from simulation are directly deployed in the real world without finetuning, achieving <strong>zero-shot transfer</strong>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="columns has-text-left">
              <h2 class="title">ConTact Framework</h2>
            </div>
            <img src="static/images/fig1_framework.png" alt="ConTact Framework" style="width: 80%;">
            <h2 class="subtitle has-text-centered">
              (a) Contrastive Learning Pre-training. (b) Spatio-temporal Encoder Architecture. (c) Downstream RL Task & Deployment.
            </h2>
            
            <div class="content has-text-left">
              <p>
                The ConTact framework addresses the sim-to-real challenge by aligning tactile data features. We first design a computationally efficient ray-casting tactile simulation model in MuJoCo MJX. Based on this, we propose a pre-training Contrastive Tactile (ConTact) framework.
              </p>
              <p>
                As depicted above, ConTact leverages contrastive learning (using a symmetric contrastive loss \(\mathcal{L}_{CTA}\)) and a spatio-temporal encoder to align tactile features across simulated and real domains. This allows us to extract unified representations for downstream DRL tasks, eliminating the need for real-world fine-tuning.
              </p>
            </div>

            <div class="columns has-text-left">
              <h3 class="title is-4">Tactile Array Simulation</h3>
            </div>
            <div class="has-text-centered">
              <img src="static/images/fig2_sensor.png" alt="Tactile Sensor" style="width: 50%;">
              <p>Real-world vs Simulated Tactile Array</p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="columns has-text-left">
              <h2 class="title">Manipulation Tasks</h2>
            </div>
            
            <img src="static/images/fig3_tasks.png" alt="SOT and COT Tasks" style="width: 60%;">
            <h2 class="subtitle has-text-centered">
              (a) Single Object Tracking (SOT). (b) Composite Object Tracking (COT).
            </h2>

            <div class="content has-text-left">
              <p>
                We introduce two kinds of manipulation tasks to evaluate our framework:
              </p>
              <ul>
                <li><strong>Single Object Tracking (SOT):</strong> Requires the robot to keep a spherical object centered on the tactile tray. This serves as a baseline to evaluate the fundamental capability of inferring object position.</li>
                <li><strong>Composite Object Tracking (COT):</strong> A more advanced challenge manipulating a composite toy car (box body + two capsule wheels). The controller must detect asymmetric loading and pressure imbalances to prevent structural collapse (car-wheel separation).</li>
              </ul>
              <p>
                For both tasks, the policy relies <strong>solely on tactile features</strong> and proprioception, without any visual input.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="columns has-text-left">
              <h2 class="title">Reconstruction & Feature Alignment</h2>
            </div>
            <div class="columns">
              <div class="column">
                <div class="item has-text-centered">
                  <img src="static/images/fig6_reconstruction.png" alt="Reconstruction" style="width: 80%;">
                  <p>Real-world Input vs Reconstructed Signal</p>
                </div>
              </div>
              <div class="column">
                <div class="item has-text-centered">
                  <img src="static/images/fig5_tsne.png" alt="Latent Space" style="width: 80%;">
                  <p>t-SNE visualization of aligned latent features</p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="columns has-text-left">
              <h2 class="title">Zero-Shot Real-World Deployment</h2>
            </div>

            <img src="static/images/fig9_realworld.png" alt="Real World Results" style="width: 100%;">
            <h2 class="subtitle has-text-centered">
              Visual results from zero-shot policy deployment on a Kinova Gen3 arm.
            </h2>

            <div class="content has-text-left">
              <p>
                We evaluate the capability to stabilize objects during dynamic movements across four distinct reference trajectories: linear, circular, lemniscate, and ascending helical. The policy demonstrates robustness against dynamic challenges, including real-time object switching, varied initial positions, and external perturbations (e.g., being tapped by a hammer).
              </p>
              <p>
                Our force-based tactile model significantly outperforms binary-signal baselines. As shown in our ablation studies, binary signals are ambiguous and unable to differentiate unstable states in the Composite Object Tracking task.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="columns has-text-left">
              <h2 class="title">Performance Demos</h2>
            </div>
            <div class="columns">
              <div class="column">
                <div class="item">
                  <video poster="" autoplay controls muted loop height="100%">
                    <source src="static/videos/sot.mp4" type="video/mp4">
                  </video>
                  <h3 class="has-text-centered">Single Object Tracking (SOT)</h3>
                </div>
              </div>

              <div class="column">
                <div class="item">
                  <video poster="" autoplay controls muted loop height="100%">
                    <source src="static/videos/cot.mp4" type="video/mp4">
                  </video>
                  <h3 class="has-text-centered">Composite Object Tracking (COT)</h3>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
   
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{contact2025,
  title={ConTact: Contrastive Tactile Alignment for Sim-to-Real Robotic Manipulation},
  author={Anonymous Authors},
  journal={Submission},
  year={2025}
}</code></pre>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was adapted from the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>